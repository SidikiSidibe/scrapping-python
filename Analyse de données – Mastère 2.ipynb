{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMEN Analyse de donnée avec Python :\n",
    "### Sujet : Scrapper l'ensemble des informations des produits du site open food facts.\n",
    "https://fr.openfoodfacts.org\n",
    "\n",
    "#### Année : 2020 - 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Présenté par :\n",
    "| Prénoms       |     Nom         |   \n",
    "| ------------- |: -------------: |\n",
    "| Aboubacar Sidiki        |        SIDIBE        |\n",
    "\n",
    "GROUPE GEMA / IA-SCHOOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procédures de scrapping\n",
    "1. Récupérer les url des produits de la page 1\n",
    "2. Récupérer les url des produits sur toutes les pages\n",
    "3. Récupérer pour chaque produits, les informations demandées\n",
    "4. Généralisation ie parcourir l'ensemble des pages pour récupérer les informations demandées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1621503319847
    }
   },
   "outputs": [],
   "source": [
    "#### import des modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython import get_ipython\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import traceback\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1621503323925
    }
   },
   "outputs": [],
   "source": [
    "urlOpenFoodFact = \"https://fr.openfoodfacts.org\" #### lien du site open food facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Récupérer les url des produits de la page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1621503326065
    }
   },
   "outputs": [],
   "source": [
    "#### en-tête html utilisée pour la coordination entre le client (navigateur) et le serveur de open food fact, simule le comportement d'un navigateur\n",
    "headers = {\"Accept\": \"image/webp,*/*\",\n",
    "\t\t\t\"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "\t\t\t\"Accept-Language\": \"fr,fr-FR;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "\t\t\t\"Connection\": \"keep-alive\",\n",
    "\t\t\t\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\"\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1621503331421
    }
   },
   "outputs": [],
   "source": [
    "res = requests.get(urlOpenFoodFact, headers = headers) #### exécute la requêtte get et renvoie la donnée non structuré pour python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1621503332382
    }
   },
   "outputs": [],
   "source": [
    "soupOpenFoodFacts = BeautifulSoup(res.text, 'html.parser') #### parsing du text en html à l'aide de BeautifulSOup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1621503333379
    }
   },
   "outputs": [],
   "source": [
    "productContent = soupOpenFoodFacts.find_all('div', attrs={'id':'search_results'})[0] #### Récupération du contenu de la balise qui contient la liste des produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1621503342899
    }
   },
   "outputs": [],
   "source": [
    "list_of_produits = productContent.find_all('a', attrs={'class':''}) #### Récupération de la liste des produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1621503345392
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_produits) #### 100 produits récupérés sur la page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1621503348971
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/produit/3274080005003/cristaline-eau-de-source\" title=\"Cristaline Eau de source - 1,5 l\">\n",
       "<div><img alt=\"Cristaline Eau de source - Produit\" height=\"100\" loading=\"lazy\" src=\"https://static.openfoodfacts.org/images/products/327/408/000/5003/front_fr.626.100.jpg\" srcset=\"https://static.openfoodfacts.org/images/products/327/408/000/5003/front_fr.626.200.jpg 2x\" width=\"30\">\n",
       "</img></div>\n",
       "<span>Cristaline Eau de source - 1,5 l</span>\n",
       "</a>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_produits[0] #### prémier élément de la liste des produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1621503352324
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/produit/3274080005003/cristaline-eau-de-source'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_produits[0]['href'] #### Premier url associé à la premier balise de la page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1621503354690
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/produit/3017620422003/nutella-ferrero'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_produits[1]['href'] #### Deuxième url associé à la premier balise de la page 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1621503360179
    }
   },
   "outputs": [],
   "source": [
    "#### récupérer les urls des produits de la page 1\n",
    "#### on concatène la partie générique du site avec l'url de chaque\n",
    "list_of_urls_product = []\n",
    "for i in range(len(list_of_produits)): #### Pour chaque élément de 0 à 100 (list_of_produits = 100)\n",
    "    list_of_urls_product.append(urlOpenFoodFact+list_of_produits[i]['href']) #### ajout de lien du produit dans la liste des urls de produit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Récupérer les url des produits sur toutes les pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Récupération du numéro de la dernière page du site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1621503365418
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8049"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paginationContent = soupOpenFoodFacts.find_all('ul', attrs={'class':'pagination'})[0] #### Récupération du contenu de la balise qui contient la pagination\n",
    "num_of_last_page = paginationContent.find_all('a')[-2].text #### Récupération du numéro de la dernière page\n",
    "num_of_last_page = int(num_of_last_page) #### convertion de la chaine en numérique\n",
    "num_of_last_page #### nombre de page disponible à l'exécution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Construction de tous les liens de la pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1621503370510
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'execution = 0.008994\n"
     ]
    }
   ],
   "source": [
    "tmps1=time.time()\n",
    "####\n",
    "\n",
    "list_of_urls_page = []\n",
    "list_of_urls_page.append(urlOpenFoodFact) #### Ajout du premier url\n",
    "for i in range(2, num_of_last_page+1): #### Pour chaque élément de 2 à num_of_last_page\n",
    "    list_of_urls_page.append(urlOpenFoodFact+\"/\"+str(i)) #### ajout du lien de la page à la liste des urls des pages\n",
    "    \n",
    "####\n",
    "tmps2=time.time()-tmps1\n",
    "print(\"Temps d'execution = %f\" %tmps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1621503376809
    }
   },
   "outputs": [],
   "source": [
    "def convert(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "      \n",
    "    return \"%dh %02dmn %02ds\" % (hour, minutes, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1621503380095
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8049"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_urls_page) #### nombre total de lien trouvé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Construction de tous les liens de tous les produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1621380376640
    }
   },
   "outputs": [],
   "source": [
    "#tmps1=time.time()\n",
    "\n",
    "#products_list = [] #### liste vide des liens des produits d'une page\n",
    "#all_products_list = [] #### liste vide de tous les liens de tous les produits de toutes les pages\n",
    "#for i in range(len(list_of_urls_page)): #### Pour chaque élément de 0 au nombre de page\n",
    "#    res = requests.get(list_of_urls_page[i]) #### on exécute la requête pour obtenir les données non structurées\n",
    "#    soupOpenFoodFacts = BeautifulSoup(res.text, 'html.parser') #### on parse le texte en html\n",
    "#    productContent = soupOpenFoodFacts.find_all('div', attrs={'id':'search_results'})[0] #### on isolé le block qui contient les produits\n",
    "#    products_list = productContent.find_all('a', attrs={'class':''}) #### on récupère la liste de tous les produits\n",
    "#    for j in range(len(products_list)): #### pour élément de la liste de produits trouvés\n",
    "#        all_products_list.append(urlOpenFoodFact+products_list[j]['href']) #### on ajoute le lien du produit dans la liste globale\n",
    "\n",
    "#tmps2=time.time()-tmps1\n",
    "#print(\"Temps d'execution de récupération de tous les liens des produits = \"+convert(tmps2))\n",
    "\n",
    "#len(all_products_list) #### le nombre total de produits trouvés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1621380377743
    }
   },
   "outputs": [],
   "source": [
    "#tmps1=time.time()\n",
    "\n",
    "#### export en csv des la liste des liens des produits trouvés\n",
    "#import pandas as pd\n",
    "#df = pd.DataFrame(all_products_list, columns=['images_url'])\n",
    "#df.to_csv('images_url.csv', index=False, encoding='utf-8')\n",
    "\n",
    "####\n",
    "#tmps2=time.time()-tmps1\n",
    "#print(\"Temps d'execution export dataframe images urls = \"+convert(tmps2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Récupérer pour chaque produits, les informations demandées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1621503389786
    }
   },
   "outputs": [],
   "source": [
    "labels_caracteristic_id = ['denomination_generique',\n",
    " 'quantite',\n",
    " 'conditionnement',\n",
    " 'marques',\n",
    " 'categories',\n",
    " 'labels_certifications_recompenses',\n",
    " 'origine_des_ingredients',\n",
    " 'lieux_de_fabrication_ou_de_transformation',\n",
    " 'code_de_tracabilite',\n",
    " 'lien_vers_la_page_du_produit_sur_le_site_officiel_du_fabricant',\n",
    " 'magasins',\n",
    " 'pays_de_vente'] #### liste les labels des caractéristiques des produits transformés en id\n",
    "\n",
    "labels_sub_trace_id = ['substances_ou_produits_provoquant_des_allergies_ou_intolerances','traces_eventuelles'] #### liste les labels des Substances ou produits des produits transformés en id\n",
    "labels_details_analysis = ['additifs', 'vitamines_ajoutees', 'mineraux_ajoutes'] #### liste les labels des Analyse des ingrédients des produits transformés en id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1621503393070
    }
   },
   "outputs": [],
   "source": [
    "def index_in_list(a_list, index):\n",
    "    \"\"\"\n",
    "    vérifie si l'index existe dans une liste\n",
    "    \n",
    "    :param a_list : la liste\n",
    "    :type a_list : List\n",
    "    \n",
    "    :returns : resultat de la vérification 1 si l'index est trouvé sinon 0.\n",
    "    :rtype : boolean.\n",
    "    \"\"\"\n",
    "    return index < len(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1621503394853
    }
   },
   "outputs": [],
   "source": [
    "def transform_label_to_id(caracteristic_list):\n",
    "    \"\"\"    \n",
    "    tranforme les labels de liste en un id\n",
    "    \n",
    "    :param  caracteristic_list : la liste contenant les labels.\n",
    "    :type caracteristic_list : List.\n",
    "\n",
    "    :returns : la liste avec les labels_id.\n",
    "    :rtype : List.\n",
    "    \"\"\"\n",
    "    for i in range(len(caracteristic_list)):\n",
    "        caracteristic_list[i][0] = text_to_id(caracteristic_list[i][0])\n",
    "    return caracteristic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1621503397234
    }
   },
   "outputs": [],
   "source": [
    "def split_list_with_xa0(list_el):\n",
    "    \"\"\"\n",
    "    Split les chaines de caractères disponibles dans une liste. La valeur du split est '\\xa0:'\n",
    "    \n",
    "    :param list_el : liste des chaines de caractères\n",
    "    :type list_el : List\n",
    "    \n",
    "    :return : la liste des chaines de caractères splitées\n",
    "    :rtype : List\n",
    "    \"\"\"\n",
    "    return list(map(lambda x: x.text.split('\\xa0:'),list_el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1621503399424
    }
   },
   "outputs": [],
   "source": [
    "def check_string_exist(el, list_el):\n",
    "    \"\"\"    \n",
    "    vérifie si un élément existe dans la liste\n",
    "    \n",
    "    :param el : L'element à rechercher dans la liste.\n",
    "    :type el : String.\n",
    "    :param list_el : la liste dans liste le recherche doit être effectuée.\n",
    "    :type list_el : list.\n",
    "\n",
    "    :returns : le resultat de la recherche sous forme boolean.\n",
    "    :rtype : Boolean.\n",
    "    \"\"\"\n",
    "    return list_el.count(el) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gather": {
     "logged": 1621503404307
    }
   },
   "outputs": [],
   "source": [
    "def strip_accents(text):\n",
    "    \"\"\"\n",
    "    Supprime les accents dans une chaîne de caractère.\n",
    "\n",
    "    :param text : La chaîne de caractères d'entrée.\n",
    "    :type text : Chaîne.\n",
    "\n",
    "    :returns : La chaîne de caractères traitée.\n",
    "    :rtype : String.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8') #### chaque caractère est codé par un codepoint UTF-8 représenté par un nombre hexadécimal\n",
    "    except (TypeError, NameError):\n",
    "        pass #### on continue si il y une erreur\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = text.encode('ascii', 'ignore') #### transforme une str en bytes\n",
    "    text = text.decode(\"utf-8\") #### transforme les bytes en str\n",
    "    return str(text) #### conversion de la valeur retournée en string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gather": {
     "logged": 1621503406867
    }
   },
   "outputs": [],
   "source": [
    "def text_to_id(text):\n",
    "    \"\"\"\n",
    "    Convertit le texte d'entrée en identifiant.\n",
    "\n",
    "    :param text : La chaîne de caractères d'entrée.\n",
    "    :type text : Chaîne.\n",
    "\n",
    "    :returns : La chaîne de caractères traitée.\n",
    "    :rtype : String.\n",
    "    \"\"\"\n",
    "    text = strip_accents(text.lower()) #### on supprime les accents\n",
    "    text = re.sub('[ ]+', '_', text) #### on remplace les espaces par un tiret de 8 (_)\n",
    "    text = re.sub('[^0-9a-zA-Z_-]', '', text) #### on supprime les valeurs numériques\n",
    "    return text #### l'identifiant de la chaine est retourné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1621503419216
    }
   },
   "outputs": [],
   "source": [
    "def get_label_id_list(label_list):\n",
    "    \"\"\"    \n",
    "    récupère la liste des label_id contenu dans la liste\n",
    "    \n",
    "    :param  label_list : la liste contenant les labels_id.\n",
    "    :type label_list : List.\n",
    "\n",
    "    :returns : la liste avec les labels_id.\n",
    "    :rtype : List.\n",
    "    \"\"\"\n",
    "    label_id_list = [] #### on initialise la liste des id\n",
    "    for i in range(len(label_list)): #### pour chaque élément de la liste\n",
    "        label_id_list.append(text_to_id(label_list[i][0].strip())) #### on ajoute dans la liste les ids récuperés\n",
    "    return label_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1621503424547
    }
   },
   "outputs": [],
   "source": [
    "def delete_detail_value(list_el):\n",
    "    \"\"\"\n",
    "    Supprime dans la liste l'élément dont la valeur est égale à '_detail_de_lanalyse_des_ingredients__'\n",
    "    \n",
    "    :param list_el : liste des éléments\n",
    "    :type list_el : List\n",
    "    \n",
    "    :return : la liste sans la valeur du filtre\n",
    "    :rtype : List\n",
    "    \"\"\"\n",
    "    index_list = []\n",
    "    for i in range(len(list_el)): #### pour chaque élément de la liste\n",
    "        value = str(list_el[i][0])\n",
    "        if(value == '_detail_de_lanalyse_des_ingredients__' or value == '_detail_de_lanalyse_des_ingredients__nous_avons_besoin_de_votre_aide_' or value == '_si_ce_produit_a_une_liste_dingredients_en_francais_merci_de_lajouter_modifier_la_fiche'): #### on vérifie si le premier élément est égale à '_detail_de_lanalyse_des_ingredients__'\n",
    "             index_list.append(i) #### on stock l'index du item à supprimer dans la liste\n",
    "    for j in index_list: del list_el[j] #### on supprime l'élément de la liste à l'index indiqué\n",
    "    return list_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1621503426596
    }
   },
   "outputs": [],
   "source": [
    "def get_value_from_list(key, list_el):\n",
    "    \"\"\"    \n",
    "    récupère la valeur associée à la clé passée en paramètre dans le dictionnaire\n",
    "    \n",
    "    :param  list_el : la liste des valeurs.\n",
    "    :type list_el : List.\n",
    "    \n",
    "    :param  key : la clé.\n",
    "    :type key : string\n",
    "\n",
    "    :returns : la valeur associée à la clé du dictionnaire.\n",
    "    :rtype : String.\n",
    "    \"\"\"\n",
    "    list_el = delete_detail_value(list_el)\n",
    "    list_el_dict = dict(list_el) #### on convertie la liste en dictionnaire\n",
    "    return list_el_dict[key].strip() #### on retourne la valeur du dictionnaire donc la clé est 'key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1621503429402
    }
   },
   "outputs": [],
   "source": [
    "def build_caracteritics_product_values(label_id_list,list_el):\n",
    "    \"\"\"    \n",
    "    récupère la liste des label_id contenu dans la liste\n",
    "    \n",
    "    :param  label_list : la liste des éléments\n",
    "    :type label_list : List.\n",
    "    \n",
    "    :param  label_id_list : la liste des ids.\n",
    "    :type label_list : List.\n",
    "\n",
    "    :returns : la liste avec les labels_id.\n",
    "    :rtype : List.\n",
    "    \"\"\"\n",
    "    all_caracteristic_list = [] #### on initialise la liste à retourner\n",
    "    list_el = split_list_with_xa0(list_el) #### on split les contenus de la liste\n",
    "    list_el = transform_label_to_id(list_el) #### on transforme les labels de la liste en id\n",
    "    caracteristic_list_id = get_label_id_list(list_el) #### on récupère la liste des labels\n",
    "    for i in range(len(label_id_list)): #### pour chaque élément de la liste des ids\n",
    "        if check_string_exist(label_id_list[i], caracteristic_list_id): #### on vérifie si un élément de la label_id_list à la position i se trouve dans la liste id\n",
    "            all_caracteristic_list.append([label_id_list[i],get_value_from_list(label_id_list[i], list_el)]) #### on ajoute la valeur de la clé trouve dans le dictionnaire\n",
    "        else: #### sinon\n",
    "            all_caracteristic_list.append([label_id_list[i],'XXX']) #### on ajoute la valeur 'XXX'\n",
    "    return dict(all_caracteristic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1621503434949
    }
   },
   "outputs": [],
   "source": [
    "def parse_string(value):\n",
    "    \"\"\"\n",
    "    Parse la chaine en supprimant \\n \\t \\r\n",
    "    \n",
    "    :param value : la valeur de la chaine à parser\n",
    "    :type value : String\n",
    "    \n",
    "    :return : la chaine parsée\n",
    "    :rtype : String\n",
    "    \"\"\"\n",
    "    if value is np.nan:\n",
    "        return value\n",
    "    else:\n",
    "        chaine = value.replace('\\n', ',')\n",
    "        chaine = \" \".join(chaine.split()).rstrip(',').strip(',').strip()\n",
    "        return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1621503436383
    }
   },
   "outputs": [],
   "source": [
    "def get_ingredient_analysis(content):\n",
    "    \"\"\"\n",
    "    récupère l'analyse des ingrédients à partir du contenu\n",
    "    \n",
    "    :param content : le block contenant le resulta de l'analyse\n",
    "    :type content : list html\n",
    "    \n",
    "    :return : \n",
    "    \"\"\"\n",
    "    if len(content) == 0:\n",
    "        return {'ingredients_analysis': 'XXX'}\n",
    "    content_split = split_list_with_xa0(content)\n",
    "    for el in content_split:\n",
    "        el[1] = parse_string(el[1])\n",
    "    return {'ingredients_analysis': el[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1621503438598
    }
   },
   "outputs": [],
   "source": [
    "def get_compare_value(label_list, value_list):\n",
    "    \"\"\"    \n",
    "    récupère la comparaison avec les valeurs moyennes des produits de même catégorie\n",
    "    \n",
    "    :param  label_list : la liste des labels\n",
    "    :type label_list : List.\n",
    "    \n",
    "    :param  value_list : la liste des valeurs.\n",
    "    :type value_list : List.\n",
    "\n",
    "    :returns : la chaine contenant les valeurs moyennes.\n",
    "    :rtype : String.\n",
    "    \"\"\"\n",
    "    compare_value = ''\n",
    "    if len(value_list) > len(label_list):\n",
    "        value_list = value_list[1:0]\n",
    "    for i in range(len(compare_label_list)):\n",
    "        compare_value = (compare_label_list[i]+compare_value_list[i]) + ',' + compare_value if len(compare_label_list) and len(compare_value_list) else 'XXX'\n",
    "    return compare_value if compare_value != '' else 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1621503443268
    }
   },
   "outputs": [],
   "source": [
    "def get_infos_nutri(tr_table):\n",
    "    \"\"\"    \n",
    "    récupère la table sur les informations nutritionnelles\n",
    "    \n",
    "    :param  tr_table : la liste des éléments de la table.\n",
    "    :type tr_table : List.\n",
    "\n",
    "    :returns : un dictionnaire de données.\n",
    "    :rtype : List.\n",
    "    \"\"\"\n",
    "    item = []\n",
    "    all_items = []\n",
    "    if len(tr_table) == 0:\n",
    "            return [['energie_kj', 'XXX'],['energie_kcal', 'XXX'],['energie', 'XXX'],['matieres_grasses__lipides', 'XXX'],['glucides', 'XXX'],['proteines', 'XXX'],['sel', 'XXX'],['score_nutritionnel_-_france', 'XXX']]\n",
    "    for i in range(len(tr_table)):\n",
    "        item = []\n",
    "        item.append(text_to_id(parse_string(tr_table[i].find('td', attrs={'class':'nutriment_label'}).text)))\n",
    "        item.append(parse_string(tr_table[i].find('td', attrs={'class':'nutriment_value'}).text if tr_table[0].find('td', attrs={'class':'nutriment_value'}) else 'XXX'))\n",
    "        all_items.append(item)\n",
    "    return dict(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1621503446383
    }
   },
   "outputs": [],
   "source": [
    "soupProduct = BeautifulSoup(requests.get('https://fr.openfoodfacts.org/produit/3017620422003/nutella-ferrero').text, 'html.parser') #### récupération du html et parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1621503447831
    }
   },
   "outputs": [],
   "source": [
    "contentInfos = soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/Product'})[0] if len(soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/Product'})) else soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/DietarySupplement'})[0] if len(soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/Product'})[0] if len(soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/Product'})) else soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/DietarySupplement'})) else [] #### récupération de la balise qui contient les informations démandées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "gather": {
     "logged": 1621503451242
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### nova score\n",
    "contentInfos.find_all('a',href='/nova')[1].find('img')['alt'].split('-')[0].strip() if index_in_list(contentInfos.find_all('a',href='/nova'),1) else 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gather": {
     "logged": 1621503454996
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### nutriscore\n",
    "contentInfos.find_all('a',href='/nutriscore')[1].find('img')['alt'].split(':')[1].strip() if index_in_list(contentInfos.find_all('a',href='/nutriscore'),1) else 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "gather": {
     "logged": 1621503458552
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ecoscore\n",
    "contentInfos.find_all('a',href='/ecoscore')[2].find('img')['alt'].split(' ')[1].strip() if index_in_list(contentInfos.find_all('a',href='/ecoscore'),1) else 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "gather": {
     "logged": 1621503462192
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nutella - Ferrero - 400\\xa0g'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Nom du Produit\n",
    "contentInfos.find_all('h1', attrs={'property':'food:name'})[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "gather": {
     "logged": 1621503463956
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3017620422003'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Code-barres (EAN/EAN-13)\n",
    "contentInfos.find_all('span', attrs={'property':'food:code'})[0].text if index_in_list(contentInfos.find_all('span', attrs={'property':'food:code'}),0) else 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "gather": {
     "logged": 1621503467792
    }
   },
   "outputs": [],
   "source": [
    "caracteristicsContent = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[0] #### block qui contient les informations sur les caractéristiques d'un produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "gather": {
     "logged": 1621503472962
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'denomination_generique': 'Pâte à tartiner aux noisettes et au cacao',\n",
       " 'quantite': '400 g',\n",
       " 'conditionnement': 'Verre, Couvercle, Plastique, Pot, Opercule, Plaque en carton',\n",
       " 'marques': 'Ferrero, Nutella',\n",
       " 'categories': 'Produits à tartiner, Petit-déjeuners, Aides culinaires, Produits à tartiner sucrés, Aides à la pâtisserie, Pâtes à tartiner, Pâtes à tartiner aux noisettes, Pâtes à tartiner au chocolat, Pâtes à tartiner aux noisettes et au cacao, Aide culinaire sucrée',\n",
       " 'labels_certifications_recompenses': 'Sans gluten, Point Vert',\n",
       " 'origine_des_ingredients': \"Australie, Brésil, Chili, Côte d'Ivoire, Ghana, Inde, Indonésie, Italie, Malaisie, Mexique, Nigeria, Papouasie-Nouvelle-Guinée, Turquie\",\n",
       " 'lieux_de_fabrication_ou_de_transformation': 'France',\n",
       " 'code_de_tracabilite': 'NON COMMUNIQUÉ',\n",
       " 'lien_vers_la_page_du_produit_sur_le_site_officiel_du_fabricant': 'https://www.nutella.com/fr/fr/produits/n...',\n",
       " 'magasins': 'Bi1, Magasins U, Carrefour, Franprix, Auchan',\n",
       " 'pays_de_vente': 'Algérie, Autriche, Belgique, Canada, France, Allemagne, Italie, Luxembourg, Mexique, Maroc, Pays-Bas, Portugal, Sénégal, Espagne, Suisse, Tunisie, Royaume-Uni, États-Unis'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### caractéristiques des produits\n",
    "caracteristic_list = caracteristicsContent.findAll('p') #### on récupère le bloc qui contient les caractéristiques des produits\n",
    "build_caracteritics_product_values(labels_caracteristic_id, caracteristic_list) #### on construit un dictionnaire avec les valeurs trouvées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "gather": {
     "logged": 1621503475695
    }
   },
   "outputs": [],
   "source": [
    "ingredientsContent = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "gather": {
     "logged": 1621503477945
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sucre, huile de palme, noisettes 13%, lait écrémé en poudre 8,7%, cacao maigre 7,4%, émulsifiants: lécithines [soja] ; vanilline. Sans gluten'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### liste des ingrédients\n",
    "ingredient_list = ingredientsContent.find_all('div', attrs={'property':'food:ingredientListAsText'})[0].text if ingredientsContent.find_all('div', attrs={'property':'food:ingredientListAsText'}) else 'XXX'\n",
    "ingredient_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "gather": {
     "logged": 1621503479890
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'substances_ou_produits_provoquant_des_allergies_ou_intolerances': 'Lait, Fruits à coque, Soja',\n",
       " 'traces_eventuelles': 'XXX'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Substances ou produits provoquant des allergies ou intolérances :\n",
    "sub_trace_list = ingredientsContent.find_all('p', attrs={'class':'', 'id':''})[:2]\n",
    "build_caracteritics_product_values(labels_sub_trace_id, sub_trace_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "gather": {
     "logged": 1621503484679
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ingredients_analysis': \"Huile de palme, ,,Non végétalien, ,,→ L'analyse est basée uniquement sur les ingrédients listés et ne prend pas en compte les méthodes de fabrication.\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Analyse des ingrédients :\n",
    "ingredients_analysis = ingredientsContent.find_all('p', attrs={'id':'ingredients_analysis'})\n",
    "get_ingredient_analysis(ingredients_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "gather": {
     "logged": 1621503487074
    }
   },
   "outputs": [],
   "source": [
    "#### Détail de l'analyse des ingrédients:\n",
    "detail_analysis = ingredientsContent.find_all('div', attrs={'class':'columns'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "gather": {
     "logged": 1621503490657
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additifs': 'E322 - Lécithines',\n",
       " 'vitamines_ajoutees': 'XXX',\n",
       " 'mineraux_ajoutes': 'XXX'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_caracteritics_product_values(labels_details_analysis, detail_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gather": {
     "logged": 1621503493607
    }
   },
   "outputs": [],
   "source": [
    "nutritionnelle_content = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[2] if len(contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})) != 0 else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "gather": {
     "logged": 1621503496463
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30.9 g Matières grasses / Lipides en quantité élevée , 10.6 g Acides gras saturés en quantité élevée , 56.3 g Sucres en quantité élevée , 0.107 g Sel en faible quantité'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Repères nutritionnels pour 100 g\n",
    "repere_nutri = parse_string(nutritionnelle_content.find_all('div', attrs={'class':'small-12 xlarge-6 columns'})[1].text).split(',,,,')[1].strip() if index_in_list(nutritionnelle_content.find_all('div', attrs={'class':'small-12 xlarge-6 columns'}),1) and index_in_list(parse_string(nutritionnelle_content.find_all('div', attrs={'class':'small-12 xlarge-6 columns'})[1].text).split(',,,,'),1) else 'XXX'\n",
    "repere_nutri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_in_list(nutritionnelle_content.find_all('div', attrs={'class':'small-12 xlarge-6 columns'}),1)\n",
    "index_in_list(parse_string(nutritionnelle_content.find_all('div', attrs={'class':'small-12 xlarge-6 columns'})[1].text).split(',,,,'),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "gather": {
     "logged": 1621503499674
    }
   },
   "outputs": [],
   "source": [
    "#### Comparaison avec les valeurs moyennes des produits de même catégorie : \n",
    "compare_label_list = list(map(lambda x: parse_string(x.text), nutritionnelle_content.find_all('label')))[:-2] if len(nutritionnelle_content) != 0 else [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "gather": {
     "logged": 1621503502652
    }
   },
   "outputs": [],
   "source": [
    "compare_value_list = list(map(lambda x:x.text.strip(), nutritionnelle_content.find_all('a' , attrs={'title':''}))) if nutritionnelle_content.find_all('a' , attrs={'title':''}) and len(nutritionnelle_content) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "gather": {
     "logged": 1621503505232
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Produits à tartiner(20886 produits),Petit-déjeuners(15325 produits),Produits à tartiner sucrés(1781 produits),Pâtes à tartiner(1256 produits),Aides culinaires(1022 produits),Pâtes à tartiner au chocolat(916 produits),Pâtes à tartiner aux noisettes(778 produits),Pâtes à tartiner aux noisettes et au cacao(519 produits),Aides à la pâtisserie(90 produits),Aide culinaire sucréeDétail du calcul du Nutri-Score »,'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_compare_value(compare_label_list, compare_value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "gather": {
     "logged": 1621503512605
    }
   },
   "outputs": [],
   "source": [
    "nutritionnelle_table = nutritionnelle_content.find_all('table', attrs={'id':'nutrition_data_table', 'class':'data_table'})[0] if nutritionnelle_content and nutritionnelle_content.find_all('table', attrs={'id':'nutrition_data_table', 'class':'data_table'}) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "gather": {
     "logged": 1621503515118
    }
   },
   "outputs": [],
   "source": [
    "tr_table = nutritionnelle_table.find_all('tr', attrs={'class':'nutriment_main'}) if len(nutritionnelle_table) and nutritionnelle_table.find_all('tr', attrs={'class':'nutriment_main'}) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "gather": {
     "logged": 1621503517667
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energie_kj': '2 252 kj',\n",
       " 'energie_kcal': '539 kcal',\n",
       " 'energie': '2 252 kj(539 kcal)',\n",
       " 'matieres_grasses__lipides': '30,9 g',\n",
       " 'glucides': '57,5 g',\n",
       " 'proteines': '6,3 g',\n",
       " 'sel': '0,107 g',\n",
       " 'score_nutritionnel_-_france': '26'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Informations nutritionnelles\n",
    "information_nutritionnelle = get_infos_nutri(tr_table)\n",
    "information_nutritionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "gather": {
     "logged": 1621503553097
    }
   },
   "outputs": [],
   "source": [
    "#### recyclage\n",
    "recyclage_content = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[3] if len(contentInfos) and contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'}) and index_in_list(contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'}),3) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "gather": {
     "logged": 1621503563779
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 couvercle plastique blanc opaque PP à jeter, 1 plaque en carton PAP 21 à recycler, 1 opercule en carton C/PAP 82 à recycler, 1 pot en verre à recycler'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recyclage = parse_string(recyclage_content.find('p').text) if len(recyclage_content) else 'XXX'\n",
    "recyclage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Généralisation ie parcourir l'ensemble des pages pour récupérer les informations demandées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "gather": {
     "logged": 1621523949469
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk start : 0\n",
      "chunk end : 50000\n",
      "scrapping start ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tmps1=time.time()\n",
    "for chunk in pd.read_csv(\"images_url.csv\", chunksize=50000):\n",
    "    tmps1=time.time()\n",
    "    food_infos = []\n",
    "    print('chunk start : '+str(chunk.index.start))\n",
    "    print('chunk end : '+str(chunk.index.stop))\n",
    "    print('scrapping start ...')\n",
    "    #### scrapping des\n",
    "    for j in chunk.index:\n",
    "        try:\n",
    "            res = requests.get(str(chunk['images_url'][j]), headers = headers)\n",
    "            soupProduct = BeautifulSoup(res.text, 'html.parser')\n",
    "            contentInfos = soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/Product'})[0] if len(soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/Product'})) else soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/DietarySupplement'})[0] if len(soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/Product'})[0] if len(soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/Product'})) else soupProduct.find_all('div', attrs={'itemscope':'', 'itemtype':'https://schema.org/DietarySupplement'})) else [] #### récupération de la balise qui contient les informations démandées\n",
    "            if len(contentInfos):\n",
    "                \"\"\"\n",
    "                #### Nom du Produit\n",
    "                product_name = contentInfos.find_all('h1', attrs={'property':'food:name'})[0].text\n",
    "\n",
    "                #### Code-barres (EAN/EAN-13)\n",
    "                code_barre = contentInfos.find_all('span', attrs={'property':'food:code'})[0].text if index_in_list(contentInfos.find_all('span', attrs={'property':'food:code'}),0) else 'XXX'\n",
    "\n",
    "                #### nova score\n",
    "                novascore = contentInfos.find_all('a',href='/nova')[1].find('img')['alt'].split('-')[0].strip() if index_in_list(contentInfos.find_all('a',href='/nova'),1) else 'XXX'\n",
    "\n",
    "                #### nutriscore\n",
    "                nutriscore = contentInfos.find_all('a',href='/nutriscore')[1].find('img')['alt'].split(':')[1].strip() if index_in_list(contentInfos.find_all('a',href='/nutriscore'),1) else 'XXX'\n",
    "\n",
    "                #### ecoscore\n",
    "                ecoscore = contentInfos.find_all('a',href='/ecoscore')[2].find('img')['alt'].split(' ')[1].strip() if index_in_list(contentInfos.find_all('a',href='/ecoscore'),1) else 'XXX'\n",
    "                #### caractéristiques des produits\n",
    "                caracteristicsContent = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[0] #### block qui contient les informations sur les caractéristiques d'un produit\n",
    "                caracteristic_list_value = caracteristicsContent.findAll('p') #### on récupère le bloc qui contient les caractéristiques des produits\n",
    "                caracteristics = build_caracteritics_product_values(labels_caracteristic_id, caracteristic_list_value) #### on construit un dictionnaire avec les valeurs trouvées\n",
    "                denomination_generique = caracteristics['denomination_generique']\n",
    "                quantite = caracteristics['quantite']\n",
    "                conditionnement = caracteristics['conditionnement']\n",
    "                marques = caracteristics['marques']\n",
    "                categories = caracteristics['categories']\n",
    "                labels_certifications_recompenses = caracteristics['labels_certifications_recompenses']\n",
    "                origine_des_ingredients = caracteristics['origine_des_ingredients']\n",
    "                lieux_de_fabrication_ou_de_transformation = caracteristics['lieux_de_fabrication_ou_de_transformation']\n",
    "                code_de_tracabilite = caracteristics['code_de_tracabilite']\n",
    "                lien_vers_la_page_du_produit_sur_le_site_officiel_du_fabricant = caracteristics['lien_vers_la_page_du_produit_sur_le_site_officiel_du_fabricant']\n",
    "                magasins = caracteristics['magasins']\n",
    "                pays_de_vente = caracteristics['pays_de_vente']\n",
    "\n",
    "                ingredientsContent = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[1]\n",
    "\n",
    "                #### Substances ou produits provoquant des allergies ou intolérances :\n",
    "                sub_trace_list = ingredientsContent.find_all('p', attrs={'class':'', 'id':''})[:2]\n",
    "                substances_ou_produits_provoquant_des_allergies_ou_intolerances = build_caracteritics_product_values(labels_sub_trace_id, sub_trace_list)['substances_ou_produits_provoquant_des_allergies_ou_intolerances']\n",
    "                traces_eventuelles = build_caracteritics_product_values(labels_sub_trace_id, sub_trace_list)['traces_eventuelles']\n",
    "\n",
    "                #### Analyse des ingrédients :\n",
    "                ingredients_analysis = ingredientsContent.find_all('p', attrs={'id':'ingredients_analysis'})\n",
    "                ingredients_analysis = get_ingredient_analysis(ingredients_analysis)['ingredients_analysis']\n",
    "\n",
    "                #### Détail de l'analyse des ingrédients:\n",
    "                detail_analysis = ingredientsContent.find_all('div', attrs={'class':'columns'})\n",
    "                additifs = build_caracteritics_product_values(labels_details_analysis, detail_analysis)['additifs']\n",
    "                vitamines_ajoutees = build_caracteritics_product_values(labels_details_analysis, detail_analysis)['vitamines_ajoutees']\n",
    "                mineraux_ajoutes = build_caracteritics_product_values(labels_details_analysis, detail_analysis)['mineraux_ajoutes']\n",
    "                \"\"\"\n",
    "                #### Repères nutritionnels pour 100 g\n",
    "                nutritionnelle_content = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[2] if len(contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})) != 0 else []\n",
    "                reperes_nutritionnels = parse_string(nutritionnelle_content.find_all('div', attrs={'class':'small-12 xlarge-6 columns'})[1].text).split(',,,,')[1].strip() if index_in_list(nutritionnelle_content.find_all('div', attrs={'class':'small-12 xlarge-6 columns'}),1) and index_in_list(parse_string(nutritionnelle_content.find_all('div', attrs={'class':'small-12 xlarge-6 columns'})[1].text).split(',,,,'),1) else 'XXX'        \n",
    "                \"\"\"\n",
    "                compare_label_list = list(map(lambda x: parse_string(x.text), nutritionnelle_content.find_all('label')))[:-2] if len(nutritionnelle_content) != 0 else [] \n",
    "                compare_value_list = list(map(lambda x:x.text.strip(), nutritionnelle_content.find_all('a' , attrs={'title':''}))) if nutritionnelle_content.find_all('a' , attrs={'title':''}) and len(nutritionnelle_content) else []\n",
    "                compare_value_mean = get_compare_value(compare_label_list, compare_value_list)\n",
    "\n",
    "                #### table information nutritionnelle\n",
    "                nutritionnelle_content = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[2] if len(contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})) != 0 else []\n",
    "                nutritionnelle_table = nutritionnelle_content.find_all('table', attrs={'id':'nutrition_data_table', 'class':'data_table'})[0] if nutritionnelle_content and nutritionnelle_content.find_all('table', attrs={'id':'nutrition_data_table', 'class':'data_table'}) else []\n",
    "                tr_table = nutritionnelle_table.find_all('tr', attrs={'class':'nutriment_main'}) if len(nutritionnelle_table) and nutritionnelle_table.find_all('tr', attrs={'class':'nutriment_main'}) else []\n",
    "                energie_kj = get_infos_nutri(tr_table)['energie_kj'] if 'energie_kj' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                energie_kcal = get_infos_nutri(tr_table)['energie_kcal'] if 'energie_kcal' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                energie = get_infos_nutri(tr_table)['energie'] if 'energie' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                matieres_grasses__lipides = get_infos_nutri(tr_table)['matieres_grasses__lipides'] if energie_kj in get_infos_nutri(tr_table) else 'XXX'\n",
    "                glucides = get_infos_nutri(tr_table)['glucides'] if 'glucides' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                proteines = get_infos_nutri(tr_table)['proteines'] if 'proteines' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                silice = get_infos_nutri(tr_table)['silice'] if 'silice' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                potassium = get_infos_nutri(tr_table)['potassium'] if 'potassium' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                chlorure = get_infos_nutri(tr_table)['chlorure'] if 'chlorure' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                calcium = get_infos_nutri(tr_table)['calcium'] if 'calcium' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                ph = get_infos_nutri(tr_table)['ph'] if 'ph' in get_infos_nutri(tr_table)else 'XXX'\n",
    "                sel = get_infos_nutri(tr_table)['sel'] if 'sel' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                fibres_alimentaires = get_infos_nutri(tr_table)['fibres_alimentaires'] if 'fibres_alimentaires' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                alcool = get_infos_nutri(tr_table)['alcool'] if 'alcool' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                bicarbonate = get_infos_nutri(tr_table)['bicarbonate'] if 'bicarbonate' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                fluorure = get_infos_nutri(tr_table)['fluorure'] if 'fluorure' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                nitrate = get_infos_nutri(tr_table)['nitrate'] if 'nitrate' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                sulfate = get_infos_nutri(tr_table)['sulfate'] if 'sulfate' in get_infos_nutri(tr_table) else 'XXX'\n",
    "                score_nutritionnel_france = get_infos_nutri(tr_table)['score_nutritionnel_-_france'] if 'score_nutritionnel_-_france' in get_infos_nutri(tr_table) else 'XXX'\n",
    "\n",
    "                #### recyclage\n",
    "                recyclage_content = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[3] if len(contentInfos) and contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'}) else []\n",
    "                recyclage = parse_string(recyclage_content.find('p').text) if len(recyclage_content) else 'XXX'\n",
    "\n",
    "                ingredientsContent = contentInfos.find_all('div', attrs={'class':'medium-12 large-8 xlarge-8 xxlarge-8 columns'})[1]\n",
    "                #### liste des ingrédients\n",
    "                ingredient_list = ingredientsContent.find_all('div', attrs={'property':'food:ingredientListAsText'})[0].text if ingredientsContent.find_all('div', attrs={'property':'food:ingredientListAsText'}) else 'XXX'\n",
    "                \"\"\"\n",
    "                food_infos.append([reperes_nutritionnels])\n",
    "            else:\n",
    "                print(\"lien \"+str(j)+\" : \"+chunk['images_url'][j])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"lien \"+str(j)+\" : \"+chunk['images_url'][j])\n",
    "            print(e)\n",
    "            traceback.print_exc()\n",
    "            tmps2=time.time()-tmps1\n",
    "            print(\"Temps d'execution avant l'erreur = \"+convert(tmps2))\n",
    "            continue\n",
    "    print('scrapping end ...' + str(chunk.index.stop))\n",
    "    tmps2=time.time()-tmps1\n",
    "    print(\"Temps d'execution de scrapping des données des produits = \"+convert(tmps2))\n",
    "    print(\"Export dataframe to csv ...\")\n",
    "    tmps1=time.time()\n",
    "    #### export en csv des la liste des liens des produits trouvés\n",
    "    df = pd.DataFrame(food_infos, columns=['reperes_nutritionnels'])\n",
    "    df.to_csv('DataframeFoodRepereNutri'+str(chunk.index.start)+'.csv', index=False, encoding='utf-8')\n",
    "    tmps2=time.time()-tmps1\n",
    "    print(\"Fin export dataframe to csv ...\")\n",
    "    print(\"Temps d'execution export csv dataframe food = \"+convert(tmps2))\n",
    "\n",
    "tmps2=time.time()-tmps1\n",
    "print(\"Temps d'execution de global de l'ensemble = \"+convert(tmps2))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
